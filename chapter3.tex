\chapter{\Lone Adaptive Control Derivation}\label{ch:derivation}

Introduction here!!!

\section{\Lone Adaptive Control}
The \Lone adaptive controller is an evolution of the concepts implemented by \ac{MRAC}.  They are similar approaches designed to model a \ac{LTI} system with unknown constant parameters.  These parameters are adjusted to achieve the desired outcome of the error between the actual plant (system) and the referenced system model (state predictor) to asymptotically approach zero.   Adaptive control attempts to estimate the plant's unknown parameters in situ.  Parameter estimation is done using either direct or indirect architectures.  The indirect architecture attempts to estimate the system's parameters, which could be considered similar to  system identification.  Alternately the easier to implement direct architecture estimates the controller parameters explicitly.  These architectures can be seen below in Figures~\ref{fig:direct_mrac} and \ref{fig:indirect_mrac}.

\begin{figure}[h!]
 \centering
  \includegraphics[width=0.65\textwidth]{Direct_MRAC.png}
  \caption{Direct \ac{MRAC} architecture }
  \label{fig:direct_mrac}
\end{figure}

\begin{figure}[h!]
 \centering
  \includegraphics[width=0.65\textwidth]{Indirect_MRAC.png}
  \caption{Indirect \ac{MRAC} architecture }
  \label{fig:indirect_mrac}
\end{figure}

The \Lone adaptive control algorithm asserts that trying to estimate the plant uncertainties outside of the control actuators' bandwidth is overly ambitious.  The system's actuator bandwidth and the slow dynamics of the plant are most commonly the system's limiting factors, and the estimator's robustness/stability could be in question if un-modeled high frequency content exists in the plant.  % See RHORs example here? 
The \Lone adaptive control constrains the objective function by using a low-pass filter (first or second order) to band the frequency response in order to meet robustness specifications.  This low-pass filter should be tuned to a frequency response commensurate with the actuator's frequency response.  When looking at examples of where to place the low-pass filter in the direct and indirect architectures, it becomes clear that the indirect architecture is the only candidate.  Figures~\ref{fig:direct_mrac_lowpass} and \ref{fig:indirect_mrac_lowpass} illustrate the placement of the low-pass filter and its implication on the closed loop model. 

\begin{figure}[h!]
 \centering
  \includegraphics[width=0.65\textwidth]{Direct_MRAC_lowpass.png}
  \caption{Direct \ac{MRAC} architecture with low-pass filter }
  \label{fig:direct_mrac_lowpass}
\end{figure}

\begin{figure}[h!]
 \centering
  \includegraphics[width=0.65\textwidth]{Indirect_MRAC_lowpass.png}
  \caption{Indirect \ac{MRAC} architecture with low-pass filter }
  \label{fig:indirect_mrac_lowpass}
\end{figure}

 It can be seen that the low-pass filter in the direct architecture inherently changes the structure of the model with the cascading of the low-pass filter and plant block diagrams.  This change mathematically is not mirrored in the state predictor and therefore is not subtractable.  However, in the indirect case, the structure of the model is kept intact and the low-pass filter is applied to both the plant and the state predictor.  This ensures that the low-pass filter is subtractable when calculating the error state and the model's structure is kept intact.

In the primary literature for this research \cite{hovakimyan2010l1}, the author often refers to the state predictor as the reference model or companion model for the direct and indirect architectures respectively.  The reference model (direct architecture) intuitively maps the desired model response to the error feedback.  In the indirect architecture case, the error state is a result of the companion model plus the low-pass filter.  This subtle distinction is necessary because it must be accounted for when tuning the companion model with the included low-pass filter.

Many slight variations of the \Lone adaptive architectures have been derived for various use cases \cite{hovakimyan2010l1}.  Some of the following forms were studied for viability in the fixed wing \ac{UAS} use case:
\begin{itemize}
	\item \ac{SISO} with constant but unknown state parameters
	\item \ac{SISO} with time variant and/or nonlinear unknown state parameters
	\item \ac{MIMO} with constant but unknown state parameters
	\item \ac{MIMO} with time variant and/or nonlinear unknown state parameters
\end{itemize}

\ac{MIMO} control algorithms would potentially afford the controller more ability to cope with system coupling if present.  A fixed wing \ac{UAS} would exhibit coupled behavior due to the coupling present in the aerodynamics but was not chosen due to the added architectural complexity.  Unknown state parameters that are assumed to be constant or time invariant are considered matched uncertainty.  Unknown state parameters that are non-constant (time variant) and/or exhibit non-linear behavior are considered unmatched uncertainty.  The unmatched uncertainty architecture offers a more appealing solution for fixed wing use cases (asymmetric actuator failure, aerodynamic coefficients scaled by dynamic pressure, etc.), but adds a significant amount of complexity to the architecture.  In summary, the \ac{SISO} architecture with matched uncertainty was chosen for this research.  

The \ac{SISO} controller with matched uncertainty was chosen to control pitch rate $(q)$ and roll rate $(p)$ of the aircraft using two separate but parallel controllers.  This meant that the controller could be generalized to a first principles physical point mass model similar to derivations found in rigid body equations of motion.  In this implementation of the \Lone adaptive controller, the desired state $x$ to be controlled was an individual body rate (\eg $q$, $p$). 

\begin{figure}[h!]
 \centering
  \includegraphics[width=1.0\textwidth]{L1_architecture.png}
  \caption{\Lone Architecture with Matched Uncertainty Block Diagram \cite{hovakimyan2010l1} }
  \label{fig:l1_architecture}
\end{figure}

As seen in Figure~\ref{fig:l1_architecture}, the generalized \Lone architecture in block diagram form and the following elements can be identified:
\begin{itemize}
	\item[] $k_g$ - feed forward input gain
	\item[] $kD(s)$ - user described filter (second order low pass plus integrator)
	\item[] $\hat{\eta}$ - \Lone controller state
	\item[] $\dot{x}$ - first order differential equation of state model
	\item[] $\hat{x}$ - state estimate
	\item[] $\tilde{x}$ - state error
	\item[] $u$ - reference objective
	\item[] $A_m$ - Hurwitz matrix
	\item[] $b$ - input matrix
	\item[] $\hat{\omega}$ - unknown input gain coefficient
	\item[] $\hat{\theta}$ - unknown constant state coefficient
	\item[] $\hat{\sigma}$ - unknown disturbance estimate
	\item[] $\Gamma$ - adaptation gain
	\item[] $Pb$ - solution to the Lyapunov stability criterion	
\end{itemize}

It should also be noted that the architecture presented in Figure~\ref{fig:l1_architecture} includes the use of a projection operator.  The parameters for $\dot{\hat{\omega}}$, $\dot{\hat{\theta}}$, and $\dot{\hat{\sigma}}$ are all projection based adaptation laws.  This simply ensures that the adaptation stays bounded around the feasible region of parameter space.  The Lyapunov stability proofs for this architecture rely on this method to guarantee stability\cite{hovakimyan2010l1} .  More discussion on the specific application of this operator can be found in Appendix [???].

One of the main benefits of using the \ac{SISO} architecture is that the solution to the Lyapunov stability criterion ($Pb$) used in the projection based adaptation laws is greatly simplified.  

In this case, $Pb$ reduces to:
\begin{equation}
Pb = \frac{1}{2\omega_n}
\end{equation}

where $\omega_n$ is the natural frequency in rad/s for the first order companion model in discrete recursive form assuming DC gain of 1. 


%---------------------------------------------------
\section{\Lone Discrete Time Implementation}
Implementing any algorithm on actual autopilot hardware will inevitably force some if not all parts of the algorithm to be discretized.  Autopilots like the Pixhawk operate at some scheduled loop rate for executing the litany of subprograms that measure sensors, calculate navigation commands, and many more.  In the case of the Pixhawk autopilot, you can run the main loop up to 400 Hz.  At 400 Hz, there is a significant insurance that the vehicle's full frequency domain of importance will be achievable.  However, the \ac{APM} flight stack records all logged parameters also at this loop rate and can create log files larger than are reasonably desired.  There are a myriad of other reasons why the engineer would not want to run at high loop rates, but successful flight at the lowest (default of 50Hz) is desired if adequate performance of the adaptive control can be achieved.  Failures in early adaptive control were largely impart due to a very naive understanding of robustness.  Brian Anderson concludes that "it is clear that the identification time scale needs to be faster than the plant variation time scale, else identification cannot keep up" \cite{anderson2005failures}.   

\subsection{Digital Bi-Quad Filter}

The L1 adaptive control algorithm utilizes two specific elements that will require careful discretization; the companion model and the low pass filter.  The digital bi-quad filter offers a very versatile and straight forward method for accurately implementing the companion model and the low pass filter discretely using it's recursive nature.  It is a second order filter which uses a \ac{FIR} front end and an \ac{IIR} back end requiring 4 total memory blocks.  This topology allows the designer to create numerous types of filters (low pass, high pass, bandpass, etc) simply by choosing appropriate coefficients.  If a first order filter is needed then the higher order FIR/IIR terms can be set to zero.  Figure~\ref{fig:bi-quad} illustrates this filter's topology where the \ac{FIR} structure is the left two memory blocks and the \ac{IIR} structure is the right two memory blocks.

\begin{figure}[h!]
 \centering
  \includegraphics[width=1.0\textwidth]{bi-quad_filter.png}
  \caption{Digital Bi-quad Filter Architecture }
  \label{fig:bi-quad}
\end{figure}

To determine the structure of the coefficients, a bi-linear Z transform is used to convert a desired S-domain (continuous time domain) filter/model into the Z-domain (discrete time domain).  

\begin{figure}[h!]
 \centering
  \includegraphics[width=1.0\textwidth]{bi-linear_transform.png}
  \caption{Bi-linear Transform}
  \label{fig:bi-linear_transform}
\end{figure}

This derivation can be seen below for the second order low pass model:

\begin{equation}
	H(s) = \frac{1}{s^2+\frac{s}{Q}+1}
\end{equation}

where the bi-linear transform converts s to z via:

\begin{equation}
	s = \left(\frac{1}{K}\right)\left(\frac{z-1}{z+1}\right)
\end{equation}

$K$ is the 'pre-warping' factor which accounts for the transition of the vertical s-plane into the circular z-plane as seen in figure~\ref{fig:bi-linear_transform}.

where $\omega T$ is:

\begin{equation}
	\omega T = 2\pi\left(\frac{F_c}{F_s}\right)
\end{equation}

\begin{equation}
\begin{split}
	K &= tan\left(\frac{\omega T}{2}\right) \\
	&= tan\left(\pi\frac{F_c}{F_s}\right)
\end{split}
\end{equation}



$F_c$ is the desired corner frequency of the filter and $F_s$ is the sampling rate (or loop rate of the autopilot).
This 'pre-warping' is critical to ensure that the continuous time cutoff frequency desired is correctly established in the discrete implementation.  It is the engineer's discretion if pre-warping is required for the appropriate application, but the general guidance is to pre-warp the Z-domain coefficients if the desired cut-off frequency is close to Nyquist.  It was chosen for this application to always pre-warp the coefficients even though the error is small for corner frequencies which are fairly distant from Nyquist.  This was chosen simply because calculating the $tan()$ function real time on the CPU adds negligible computational strain but offers ease of tuning for the engineer.

Applying the bi-linear transform to the continuous time second order low pass filter results in:

\begin{equation}\label{eq:bi-linear}
	H(z) = \frac{1}{ \left[\left(\frac{1}{K}\right)\left(\frac{z-1}{z+1}\right)\right]^2+\frac{ \left(\frac{1}{K}\right)\left(\frac{z-1}{z+1}\right)}{Q}+1}
\end{equation}

The desired form is:

\begin{equation}\label{eq:bi-quad}
	H(z) = \frac{b_0 + b_1 z^{-1} + b_2 z^{-2}}{a_0 + a_1 z^{-1} + a_2 z^{-2}}
\end{equation}

Reducing equation~\ref{eq:bi-linear} to match the form in equation~\ref{eq:bi-quad} results in the following coefficients:

\begin{equation}
\begin{split}
	a_0 &= 1 \\
	a_1 &= \frac{2(K^2-1)}{K^2+\frac{K}{Q}+1} \\
	a_2 &= \frac{K^2-\frac{K}{Q}+1}{K^2+\frac{K}{Q}+1} \\
	b_0 &= \frac{K^2}{K^2+\frac{K}{Q}+1} \\
	b_1 &= 2b_0 \\
	b_2 &= b_0 	
\end{split}
\end{equation}

The bandwidth of the filter $Q$ can be set by the engineer.  For example, if the pass-band of the filter is desired to be flat (Butterworth) then $Q$ can be set equal to $\frac{1}{\sqrt{2}}$.  For this research the following C++ code segments were used to explicitly calculate the bi-quad low-pass filter implementation: \newline

\begin{lstlisting}
void DigitalBiquadFilter<T>::compute_params(float sample_freq, 
float cutoff_freq, biquad_params &ret) {
    ret.cutoff_freq = cutoff_freq;
    ret.sample_freq = sample_freq;

    float fr = sample_freq/cutoff_freq;
    float K = tanf(M_PI/fr);  //Pre-Warp calculation
    float c = 1.0f+2.0f*cosf(M_PI/4.0f)*K + K*K;

    ret.b0 = K*K/c;
    ret.b1 = 2.0f*ret.b0;
    ret.b2 = ret.b0;
    ret.a1 = 2.0f*(K*K-1.0f)/c;
    ret.a2 = (1.0f-2.0f*cosf(M_PI/4.0f)*K+K*K)/c;
}
\end{lstlisting}

\begin{lstlisting}
T DigitalBiquadFilter<T>::apply(const T &sample, 
const struct biquad_params &params) {
    
    T delay_element_0 = sample - _delay_element_1 * params.a1 
	    - _delay_element_2 * params.a2;
    
    T output = delay_element_0 * params.b0 
	    + _delay_element_1 * params.b1 
	    + _delay_element_2 * params.b2;

    _delay_element_2 = _delay_element_1;
    _delay_element_1 = delay_element_0;

    return output;
}

\end{lstlisting}

This implementation can be used as the \Lone low-pass filter and as the companion model.  It can be seen in the above code segment that $K$, the pre-warp factor, is explicitly calculated every iteration.

\subsection{Simplified Bi-quad First Order Model}

In the case of the companion model, a first order response may be desired.  As described in equations~\ref{eq:first_order_model} and \ref{eq:state_space_model}, the discrete first order model can be derived from a simplified Bi-quad as seen below in figure~\ref{fig:bi-quad_first_order}.  It can be seen that the first coefficient of the \ac{IIR} filter is kept from this topology.
\begin{figure}[h!]
 \centering
  \includegraphics[width=1.0\textwidth]{bi-quad_first_order.png}
  \caption{Digital Bi-quad Simplified First Order Low-pass Filter }
  \label{fig:bi-quad_first_order}
\end{figure}

The first order model can be specified by either its time constant (time in seconds to reach 63\% of steady state) or its -3dB corner frequency.  The system takes the form as seen in equation~\ref{eq:first_order_corner_model} when defined by its corner frequency.

\begin{equation}\label{eq:first_order_corner_model}
H(s)=\frac{\omega_n}{s+\omega_n}
\end{equation}

therefore the explicit calculation of the Bi-quad coefficients in this case becomes:

\begin{equation}\label{eq:first_order_coeffieicnts}
\begin{split}
	a_1&=e^{\left(\frac{-\omega_n}{F_s}\right)}  \\
	b_0&=1-a_1
\end{split}
\end{equation}

where $\omega_n$ is the -3dB corner frequency in radians per second and $F_s$ is the sampling frequency in Hz.

Therefore the discrete recursive form of the first order model becomes:

\begin{equation}
y_{i+1}=a_1y_{i-1}+b_0y_i
\end{equation}

Another form commonly seen in software form which is designed to optimize for speed takes the form:

\begin{lstlisting}
float b_0=exp(-f_c/f_s);
float out+=(in-out)*b_0;
\end{lstlisting}

\subsection{Euler vs Trapezoid Rule}

The model estimate as well as the parameter estimates for the \Lone algorithm are both numerically estimated using discrete integration.  The Euler method is a numerical procedure for solving ordinary differential equations. The Euler method as applied to discrete integration, is the fundamental method for recursively integrating a digital signal.  The algorithm takes the form: \newline
where $h$ is the uniform step size,
\begin{equation}
y_{i+1}=y_i+hf(t_i,y_i)
\end{equation}

The recursive trapezoidal method (Heun's method) takes the form:
\begin{equation}\label{eq:trapezoidal_integration}
\begin{split}
\tilde{y}_{i+1}&=y_i+hf(t_i,y_i) \\
y_{i+1}&=y_i+\frac{h}{2}[f(t_i,y_i)+f(t_{i+1},\tilde{y}_{i+1})]
\end{split}
\end{equation}

Comparing the accuracy of the two numerical methods for discretely calculating the integral of $y=e^t$ can be seen in figure~\ref{fig:trapezoidal_integration}:

\begin{figure}[h!]
 \centering
  \includegraphics[width=0.75\textwidth]{trapezoidal_integration.png}
  \caption{Euler vs Trapezoidal Integration error}
  \label{fig:trapezoidal_integration}
\end{figure}

As seen in equation~\ref{eq:trapezoidal_integration}, the recursive trapezoidal integration method only adds one more line of complexity to the algorithm for a significant gain in accuracy and therefore will be the chosen method applied for all discrete numerical integration in this research.













